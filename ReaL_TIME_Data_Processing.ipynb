{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Kafka and the required libraries**\n",
        "\n",
        "First, you'll need to have Apache Kafka installed and running. You can follow Apache Kafka's Quickstart to set up Kafka on your machine. You also need to install the confluent_kafka Python library:"
      ],
      "metadata": {
        "id": "APBsmMu2Y8zb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feWpjcHVYOW3"
      },
      "outputs": [],
      "source": [
        "pip install confluent_kafka"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Kafka Topics**\n",
        "\n",
        "Create topics in Kafka for the producer and consumer to use. I used Kafka's command-line tools to do this."
      ],
      "metadata": {
        "id": "oCU0rySoZEbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1"
      ],
      "metadata": {
        "id": "7mm1H8PFY44W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Producer Code**\n",
        "\n",
        "The producer sends data to the Kafka topic."
      ],
      "metadata": {
        "id": "eNmgqbgoZRdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import time\n",
        "\n",
        "# Configuration for Kafka Producer\n",
        "conf = {\n",
        "    'bootstrap.servers': 'localhost:9092',  # Kafka broker\n",
        "    'client.id': 'python-producer'\n",
        "}\n",
        "\n",
        "# Create Producer instance\n",
        "producer = Producer(**conf)\n",
        "\n",
        "# Function to send data to Kafka\n",
        "def delivery_report(err, msg):\n",
        "    \"\"\" Called once for each message produced to indicate delivery result.\n",
        "        Triggered by poll() or flush(). \"\"\"\n",
        "    if err is not None:\n",
        "        print(f'Message delivery failed: {err}')\n",
        "    else:\n",
        "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
        "\n",
        "# Produce data to Kafka\n",
        "for i in range(10):\n",
        "    data = f'hello {i}'\n",
        "    # Produce message\n",
        "    producer.produce('test-topic', key=str(i), value=data, callback=delivery_report)\n",
        "    # Wait up to 1 second for events. Callbacks will be invoked during\n",
        "    # this method call if the message is acknowledged.\n",
        "    producer.poll(1)\n",
        "    time.sleep(1)\n",
        "\n",
        "# Wait for any outstanding messages to be delivered and delivery report\n",
        "# callbacks to be triggered.\n",
        "producer.flush()\n"
      ],
      "metadata": {
        "id": "KA4u7UckY8hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consumer Code**\n",
        "\n",
        "The consumer reads data from the Kafka topic and processes it in real time."
      ],
      "metadata": {
        "id": "q0G6NNT4ZYpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer, KafkaError\n",
        "\n",
        "# Configuration for Kafka Consumer\n",
        "conf = {\n",
        "    'bootstrap.servers': 'localhost:9092',  # Kafka broker\n",
        "    'group.id': 'python-consumer',          # Consumer group ID\n",
        "    'auto.offset.reset': 'earliest'         # Start reading from the earliest message\n",
        "}\n",
        "\n",
        "# Create Consumer instance\n",
        "consumer = Consumer(**conf)\n",
        "\n",
        "# Subscribe to topic\n",
        "consumer.subscribe(['test-topic'])\n",
        "\n",
        "# Process messages from Kafka\n",
        "try:\n",
        "    while True:\n",
        "        msg = consumer.poll(timeout=1.0)\n",
        "        if msg is None:\n",
        "            continue\n",
        "        if msg.error():\n",
        "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                # End of partition event\n",
        "                print(f'{msg.topic()} [{msg.partition()}] reached end at offset {msg.offset()}')\n",
        "            elif msg.error():\n",
        "                raise KafkaException(msg.error())\n",
        "        else:\n",
        "            # Proper message\n",
        "            print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "finally:\n",
        "    # Close down consumer to commit final offsets.\n",
        "    consumer.close()"
      ],
      "metadata": {
        "id": "8VlptUSUZWTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}